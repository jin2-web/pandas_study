


import requests as rq
url = 'https://quotes.toscrape.com/'
quote = rq.get(url)
quote





quote.content[20:100] #html 전체코드에서 20번째 문자부터 99번 문자까지 보기
quote.content # html 전체 코드 보기 
quote.content[:1000]





from bs4 import BeautifulSoup as bs
quote_html = bs( quote.content, 'lxml' )
quote_html
quote_html.head() # <body> 태그만 보여 주기 





# 변수 = html변수명.find('태그명', class_='클래스명' )
quote_div = quote_html.find('div', class_='quote')
# find() 찾는게 여러개면 첫번째 것만 찾는다.
quote_div
# 변수 = html변수명.find_all('태그명', class_='클래스명' )
# find_all() 모든 것을 찾아서 리스트로 만든다.
quote_div = quote_html.find_all('div', class_='quote')
quote_div # 모든 것을 찾아서 리스트
quote_div[0]





quote_span = quote_div[0].find_all('span', class_='text')
quote_span





quote_span[0].text 
# <span> 명언 글자 </span> 형태에서 명언 글자 가지오기





명언 = []
for i in quote_div:
    spans = i.find_all('span', class_='text')
    if spans:
       명언.append( spans[0].text )
명언

명언2 = [ i.find_all('span', class_='text')[0].text for i in quote_div ]
#      3번                    2번                           1번
# 1번은 반복문
# 2번은 반복문의 내용
# 3번은 리스트 저장
명언2


명언 = [i.find_all('span',class_='text')[0].text for i in quote_div]
명언





quote_text = quote_html.select('div.quote > span.text')
quote_text





quote_text_list = [i.text for i in quote_text]
quote_text_list





quote_author = quote_html.select('div.quote > span > small.author')
quote_author_text = [ i.text  for i in quote_author]
quote_author_text





quote_link = quote_html.select('div.quote > span > a')
quote_link





quote_link[0]['href']
# 모든 속성을 출력해 보세요 리스트컴프리헨션을 이용해서
quote_link_list = [ i['href'] for i in quote_link ]
quote_link_list





quote_link_list = ['https://quotes.toscrape.com' + i['href'] for i in quote_link ]
quote_link_list





import requests as rq
from bs4 import BeautifulSoup as bs
import time

text_list = [] #모든 페이지 명언 리스트
author_list = [] #모든 페이지 작성자 리스트
infor_list = [] #모든 페이지 사이트 링크 리스트

for i in range(1, 100):
    url = f'https://quotes.toscrape.com/page/{i}/'
    quote = rq.get(url)
    quote_html = bs(quote.content, 'lxml')
    quote_text = quote_html.select('div.quote > span.text')
    quote_text_list = [i.text for i in quote_text] #한개의 명언 
    quote_author = quote_html.select('div.quote > span > small.author')
    quote_author_list = [i.text for i in quote_author] # 한명의 작성자
    # 작성자를 이용한 링크 주소
    quote_link = quote_html.select('div.quote > span > a')
    quote_link_list=[ 'https://quotes.toscrape.com'+i['href'] for i in quote_link ]

    if len(quote_text_list) > 0 :
        text_list.extend( quote_text_list )
        author_list.extend( quote_author_list )
        infor_list.extend( quote_link_list )
        time.sleep(1)
    else:
        break





text_list
author_list
infor_list
import pandas as pd
df = pd.DataFrame( {'text': text_list, 'author': author_list, 'infor': infor_list} )
df





import requests as rq
url = 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258'
quote = rq.get(url)

from bs4 import BeautifulSoup as bs
quote_html = bs( quote.content, 'lxml' )

quote_a=quote_html.select('dl > dd.articleSubject > a')
quote_a





quote_a[0]['title']





quote_title = [i['title'] for i in quote_a]
quote_title


import pandas as pd
df = pd.DataFrame({ 'title': quote_title })
df








import pandas as pd
url = 'https://en.wikipedia.org/wiki/List_of_countries_by_stock_market_capitalization'
df_list = pd.read_html(url) #사이트에 <table>테그를 리스트로 가져온다
df_list[2]





import requests as rq
from bs4 import BeautifulSoup as bs
import pandas as pd
url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do'
payload = {
    'method': 'searchTodayDisclosureSub',
    'currentPageSize': 15,
    'pageIndex': 1,
    'orderMode': 0,
    'orderStat': 'D',
    'forward': 'todaydisclosure_sub',
    'chose': 'S',
    'todayFlag': 'N',
    'selDate': '2025-04-23'
 }
quote = rq.post(url, data=payload) # payload 웹페이지에 대한 정보를 딕셔너리
quote
quote_html = bs(quote.content, 'lxml')
#quote_html
#여기서 날자를 4월 23일로 바꾸려면 selDate값을 바꾸기 





html_unicode = quote_html.prettify()
#html_unicode[500:1000]
#html_unicode


df = pd.read_html(html_unicode)
df





import requests as rq
from bs4 import BeautifulSoup
import pandas as pd

url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do'
payload = {
    'method': 'searchTodayDisclosureSub',
    'currentPageSize': '15',
    'pageIndex': '1',
    'orderMode': '0',
    'orderStat': 'D',
    'forward': 'todaydisclosure_sub',
    'chose': 'S',
    'todayFlag': 'N',
    'selDate': '2025-04-23'
}

data = rq.post(url, data=payload)
html = BeautifulSoup(data.content, 'html.parser')


html_unicode = html.prettify()
tbl = pd.read_html(html.prettify())

tbl[0].head()
