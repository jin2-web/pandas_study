{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정적 크롤링 실습하기\n",
    "\n",
    "각종 금융 웹사이트에는 주가, 재무정보 등 우리가 원하는 대부분의 주식 정보가 제공되고 있으며, 크롤링을 통해 이러한 데이터를 수집할 수 있다. 크롤링 혹은 스크래핑이란 웹사이트에서 원하는 정보를 수집하는 기술이다. 이번 장에서는 크롤링에 대한 간단한 설명과 예제를 살펴보겠다.\n",
    "\n",
    "```{note}\n",
    "크롤링을 할 때 주의해야 할 점이 있다. 특정 웹사이트의 페이지를 쉬지 않고 크롤링하는 행위를 무한 크롤링이라고 한다. 무한 크롤링은 해당 웹사이트의 자원을 독점하게 되어 타인의 사용을 막게 되며 웹사이트에 부하를 준다. 일부 웹사이트에서는 동일한 IP로 쉬지 않고 크롤링을 할 경우 접속을 막아버리는 경우도 있다. 따라서 하나의 페이지를 크롤링한 후 1~2초 가량 정지하고 다시 다음 페이지를 크롤링하는 것이 좋다.\n",
    "\n",
    "또한 신문기사나 책, 논문, 사진 등 저작권이 있는 자료를 통해 부당이득을 얻는다는 등의 행위를 할 경우 법적 제재를 받을 수 있다. \n",
    "\n",
    "이 책에서 설명하는 크롤링을 통해, 상업적 가치가 있는 데이터에 접근을 시도하여 발생할 수 있는 어떠한 상황에 대해서도 책임을 질 수 없다는 점을 명심하기 바란다.\n",
    "```\n",
    "\n",
    "## GET과 POST 방식 이해하기\n",
    "\n",
    "우리가 인터넷에 접속해 서버에 파일을 요청(Request)하면, 서버는 이에 해당하는 파일을 우리에게 보내준다(Response). 크롬과 같은 웹 브라우저는 이러한 과정을 사람이 수행하기 편하고 시각적으로 보기 편하도록 만들어진 것이며, 인터넷 주소는 서버의 주소를 기억하기 쉽게 만든 것이다. 우리가 서버에 데이터를 요청하는 형태는 다양하지만 크롤링에서는 주로 GET과 POST 방식을 사용한다.\n",
    "\n",
    "```{figure} image/crawl_basic/flow.png\n",
    "---\n",
    "name: flow\n",
    "---\n",
    "클라이언트와 서버 간의 요청/응답 과정\n",
    "```\n",
    "\n",
    "### GET 방식\n",
    "\n",
    "GET 방식은 인터넷 주소를 기준으로 이에 해당하는 데이터나 파일을 요청하는 것이다. 주로 클라이언트가 요청하는 쿼리를 앰퍼샌드(&) 혹은 물음표(?) 형식으로 결합해 서버에 전달한다.\n",
    "\n",
    "네이버 홈페이지에 접속한 후 [퀀트]를 검색하면, 주소 끝부분에 [&query=퀀트]가 추가되며 이에 해당하는 페이지의 내용을 보여준다. 즉, 해당 페이지는 GET 방식을 사용하고 있으며 입력 종류는 query, 입력값은 퀀트임을 알 수 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/naver_search_1.png\n",
    "---\n",
    "name: naver_search_1\n",
    "---\n",
    "네이버 검색 결과\n",
    "```\n",
    "\n",
    "[헤지펀드]를 다시 검색하면, 주소 끝부분이 [&query=헤지펀드&oquery=퀀트...]로 변경된다. 현재 입력값은 헤지펀드, 기존 입력값은 퀀트이며 이러한 과정을 통해 연관검색어가 생성됨도 유추해볼 수 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/naver_search_2.png\n",
    "---\n",
    "name: naver_search_2\n",
    "---\n",
    "네이버 재검색 결과\n",
    "```\n",
    "\n",
    "### POST 방식\n",
    "\n",
    "POST 방식은 사용자가 필요한 값을 추가해서 요청하는 방법이다. GET 방식과 달리 클라이언트가 요청하는 쿼리를 body에 넣어서 전송하므로 요청 내역을 직접 볼 수 없다. 동행복권 홈페이지에 접속해 [당첨결과] 메뉴를 확인해보자.\n",
    "\n",
    "- https://www.dhlottery.co.kr/gameResult.do?method=byWin\n",
    "\n",
    "```{figure} image/crawl_basic/lotto.png\n",
    "---\n",
    "name: lotto\n",
    "---\n",
    "회차별 당첨번호\n",
    "```\n",
    "\n",
    "이번엔 회차 바로가기를 변경한 후 [조회]를 클릭한다. 페이지의 내용은 선택일 기준으로 변경되었지만, 주소는 변경되지 않고 그대로 남아 있다. GET 방식에서는 입력 항목에 따라 웹페이지 주소가 변경되었지만, POST 방식을 사용해 서버에 데이터를 요청하는 해당 웹사이트는 그렇지 않은 것을 알 수 있다.\n",
    "\n",
    "POST 방식의 데이터 요청 과정을 살펴보려면 개발자도구를 이용해야 하며, 크롬에서는 [F12]키를 눌러 개발자도구 화면을 열 수 있다. 개발자도구 화면을 연 상태에서 다시 한번 [조회]를 클릭해보자. [Network] 탭을 클릭하면, [조회]을 클릭함과 동시에 브라우저와 서버 간의 통신 과정을 살펴볼 수 있다. 이 중 상단의 gameResult.do?method=byWin 이라는 항목이 POST 형태임을 알 수 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/lotto_post.png\n",
    "---\n",
    "name: lotto_post\n",
    "---\n",
    "크롬 개발자도구의 Network 화면\n",
    "```\n",
    "\n",
    "해당 메뉴를 클릭하면 통신 과정을 좀 더 자세히 알 수 있다. [Payload] 탭의 [Form Data]에는 서버에 데이터를 요청하는 내역이 있다. drwNo와 dwrNoList에는 선택한 회차의 숫자가 들어가있다.\n",
    "\n",
    "\n",
    "```{figure} image/crawl_basic/lotto_query.png\n",
    "---\n",
    "name: lotto_query\n",
    "---\n",
    "POST 방식의 서버 요청 내역\n",
    "```\n",
    "\n",
    "이처럼 POST 방식은 요청하는 데이터에 대한 쿼리가 GET 방식처럼 URL을 통해 전송되는 것이 아닌 body를 통해 전송되므로, 이에 대한 정보는 웹 브라우저를 통해 확인할 수 없으며, 개발자도구 화면을 통해 확인해야 한다.\n",
    "\n",
    "## 크롤링 예제\n",
    "\n",
    "일반적으로 크롤링은 {numref}`flowchart`의 과정을 따른다. 먼저, request 패키지의 `get()` 혹은 `post()` 함수를 이용해 데이터를 요청한 후 HTML을 정보를 가져오며, bs4 패키지의 함수들을 이용해 원하는 데이터를 찾는 과정으로 이루어진다. 기본적인 크롤링을 시작으로 GET 방식과 POST 방식으로 데이터를 받는 예제를 학습해 보겠다.\n",
    "\n",
    "```{figure} image/crawl_basic/flowchart.png\n",
    "---\n",
    "name: flowchart\n",
    "---\n",
    "일반적인 크롤링 과정\n",
    "```\n",
    "\n",
    "### 명언 크롤링하기\n",
    "\n",
    "크롤링의 간단한 예제로 'Quotes to Scrape' 사이트에 있는 명언을 수집하겠다.\n",
    "\n",
    "```\n",
    "https://quotes.toscrape.com/\n",
    "```\n",
    "\n",
    "해당사이트에 접속한 후, 명언에 해당하는 부분에 마우스 커서를 올려둔 후 마우스 오른쪽 버튼을 클릭하고 [검사]를 선택하면 개발자도구 화면이 나타난다. 여기서 해당 글자가 HTML 내에서 어떤 부분에 위치하는지 확인할 수 있다.\n",
    "\n",
    "- 각 네모에 해당하는 부분: [class가 quote인 div 태그]\n",
    "- 명언: 위의 태그 하부의 [class가 text인 span 태그]\n",
    "- 말한 사람은 [span 태그 하단의 class가 author인 small 태그]\n",
    "- 말한 사람에 대한 정보인 about의 링크: [a 태그 href 속성]의 속성값\n",
    "\n",
    "```{figure} image/crawl_basic/quote.png\n",
    "---\n",
    "name: quote\n",
    "---\n",
    "Quotes to Scrape의 명언부분 HTML\n",
    "```\n",
    "\n",
    "이제 위의 내용을 하나씩 크롤링 해보도록 하자. 먼저 해당 페이지의 내용을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests as rq\n",
    "url = 'https://quotes.toscrape.com/'\n",
    "quote = rq.get(url)\n",
    "quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url에 해당 주소를 입력한 후 `get()` 함수를 이용해 해당 페이지의 내용을 받았다. 이를 확인해보면 Response가 200, 즉 데이터가 이상 없이 받아졌음이 확인된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<title>Quotes to Scrape</title>\\n    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\\n    <link rel=\"stylesheet\" href=\"/static/main.css\">\\n    \\n    \\n</head>\\n<body>\\n    <div class=\"container\">\\n        <div class=\"row header-box\">\\n            <div class=\"col-md-8\">\\n                <h1>\\n                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\\n                </h1>\\n            </div>\\n            <div class=\"col-md-4\">\\n                <p>\\n                \\n                    <a href=\"/login\">Login</a>\\n                \\n                </p>\\n            </div>\\n        </div>\\n    \\n\\n<div class=\"row\">\\n    <div class=\"col-md-8\">\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote.content[20:100] #html 전체코드에서 20번째 문자부터 99번 문자까지 보기\n",
    "quote.content # html 전체 코드 보기 \n",
    "quote.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`content`를 통해 함수를 통해 받아온 내용을 확인할 수 있으며, 텍스트 형태로 이루어져있다. `BeautifulSoup()` 함수를 이용해 원하는 HTML 요소에 접근하기 쉬운 BeautifulSoup 객체로 변경할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<meta charset=\"utf-8\"/>,\n",
       " <title>Quotes to Scrape</title>,\n",
       " <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>,\n",
       " <link href=\"/static/main.css\" rel=\"stylesheet\"/>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "quote_html = bs( quote.content, 'lxml' )\n",
    "quote_html\n",
    "quote_html.head() # <body> 태그만 보여 주기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup()` 함수 내에 HTML 정보에 해당하는 `quote.content`와 파싱 방법에 해당하는 `html.parser`를 입력하면 개발자도구 화면에서 보던 것과 비슷한 형태인 BeautifulSoup 객체로 변경되며, 이를 통해 원하는 요소의 데이터를 읽어올 수 있다.\n",
    "\n",
    "```{note}\n",
    "`BeautifulSoup()` 함수는 다양한 파서를 지원하며, 그 내용은 다음과 같다.\n",
    "\n",
    "| Parser | 선언방법 | 장점 | 단점 |\n",
    "| --- | --- | --- | --- |\n",
    "| html.parser | `BeautifulSoup(내용, 'html.parser')` | 설치할 필요 없음 <br> 적당한 속도 | \n",
    "| lxml HTML parser | `BeautifulSoup(내용, 'lxml')` | 매우 빠름 | lxml 추가 설치 필요 |\n",
    "| lxml XML parser | `BeautifulSoup(내용, 'xml')` | 매우 빠름 <br> 유일하게 XML 파싱 | lxml 추가 설치 필요 |\n",
    "| html5lib | `BeautifulSoup(내용, 'html5lib')` | 웹 브라우저와 같은 방식으로 페이지 파싱. <br> 유효한 HTML5 생성 | html5lib 추가 설치 필요 <br> 매우 느림 |\n",
    "```\n",
    "\n",
    "#### `find()` 함수를 이용한 크롤링\n",
    "\n",
    "먼저 BeautifulSoup 모듈의 `find()` 함수를 통해 크롤링 하는법을 알아보자. 우리는 개발자도구 화면에서 명언에 해당하는 부분이 [class가 quote인 div 태그 → class가 text인 span 태그]에 위치하고 있음을 살펴보았다. 이를 활용해 명언만을 추출하는 방법은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
      "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
      "<a href=\"/author/Albert-Einstein\">(about)</a>\n",
      "</span>\n",
      "<div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "<a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
      "<a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
      "<a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
      "<a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
       "<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
       "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       "<a href=\"/author/Albert-Einstein\">(about)</a>\n",
       "</span>\n",
       "<div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
       "<a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
       "<a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
       "<a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
       "<a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수 = html변수명.find('태그명', class_='클래스명' )\n",
    "quote_div = quote_html.find('div', class_='quote')\n",
    "# find() 찾는게 여러개면 첫번째 것만 찾는다.\n",
    "quote_div\n",
    "# 변수 = html변수명.find_all('태그명', class_='클래스명' )\n",
    "# find_all() 모든 것을 찾아서 리스트로 만든다.\n",
    "quote_div = quote_html.find_all('div', class_='quote')\n",
    "quote_div # 모든 것을 찾아서 리스트\n",
    "quote_div[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all()` 함수를 이용할 경우 원하는 태그의 내용들을 찾아올 수 있다. 먼저 태그에 해당하는 'div'를 입력하고, class 이름인 'quote'를 입력한다. class라는 키워드는 파이썬에서 클래스를 만들 때 사용하는 키워드이므로 언더바(\\_)를 통해 중복을 피해준다. 조건에 만족하는 결과가 리스트 형태로 반환되므로, 첫번째 내용만 확인해보면 `div class=\"quote\"`에 해당하는 내용을 찾아왔으며, 이제 여기서 [class가 text인 span 태그]에 해당하는 내용을 추가로 찾도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_span = quote_div[0].find_all('span', class_='text')\n",
    "quote_span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 한번 `find_all()` 함수를 이용해 원하는 부분(`'span', class_='text'`)을 입력하면 우리가 원하던 명언에 해당하는 내용이 찾아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_span[0].text \n",
    "# <span> 명언 글자 </span> 형태에서 명언 글자 가지오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물 마지막에 `.text`를 입력하면 텍스트 데이터만을 출력할 수 있다. for문 중에서 리스트 내포 형태를 이용하여 명언에 해당하는 부분을 한번에 추출해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       " '“Try not to become a man of success. Rather become a man of value.”',\n",
       " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       " '“A day without sunshine is like, you know, night.”']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "명언 = []\n",
    "for i in quote_div:\n",
    "    spans = i.find_all('span', class_='text')\n",
    "    if spans:\n",
    "       명언.append( spans[0].text )\n",
    "명언\n",
    "\n",
    "명언2 = [ i.find_all('span', class_='text')[0].text for i in quote_div ]\n",
    "#      3번                    2번                           1번\n",
    "# 1번은 반복문\n",
    "# 2번은 반복문의 내용\n",
    "# 3번은 리스트 저장\n",
    "명언2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       " '“Try not to become a man of success. Rather become a man of value.”',\n",
       " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       " '“A day without sunshine is like, you know, night.”']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "명언 = [i.find_all('span',class_='text')[0].text for i in quote_div]\n",
    "명언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`find_all()` 함수가 아닌 `find()` 함수를 사용하면 해당 태그의 첫번째 내용만을 가져온다.\n",
    "```\n",
    "\n",
    "#### `select()` 함수를 이용한 크롤링\n",
    "\n",
    "위 예제에서는 간단하게 원하는 데이터를 찾았지만, 데이터가 존재하는 곳의 태그를 여러번 찾아 내려가야 할 경우 `find_all()` 함수를 이용하는 방법은 매우 번거롭다. `select()` 함수의 경우 좀더 쉬운 방법으로 원하는 데이터가 존재하는 태그를 입력할 수 있다. 위의 동일한 내용을 `select()` 함수를 이용해 크롤링해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“Try not to become a man of success. Rather become a man of value.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“It is better to be hated for what you are than to be loved for what you are not.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“I have not failed. I've just found 10,000 ways that won't work.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never know how strong it is until it's in hot water.”</span>,\n",
       " <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you know, night.”</span>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_text = quote_html.select('div.quote > span.text')\n",
    "quote_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`select()` 함수 내에 찾고자 하는 태그를 입력하며, 클래스명이 존재할 경우 점(.)을 붙여준다. 또한 여러 태그를 찾아 내려가야할 경우 `>` 기호를 이용해 순서대로 입력해주면 된다. 즉 'div.quote > span.text'는 [class가 quote인 div 태그] 중에서 [class가 text인 span 태그]를 찾는다. 이제 텍스트 데이터만 추출해보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       " '“Try not to become a man of success. Rather become a man of value.”',\n",
       " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       " '“A day without sunshine is like, you know, night.”']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_text_list = [i.text for i in quote_text]\n",
    "quote_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_all()` 함수를 이용한 것 보다 훨씬 간단하게 원하는 데이터를 찾을 수 있었다.\n",
    "\n",
    "이번에는 명언을 말한 사람 역시 크롤링해보도록 하자. 해당 데이터는 [class가 quote인 div 태그] 하단의 [span 태그], 다시 하단의 [class가 author인 small 태그]에 위치하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albert Einstein',\n",
       " 'J.K. Rowling',\n",
       " 'Albert Einstein',\n",
       " 'Jane Austen',\n",
       " 'Marilyn Monroe',\n",
       " 'Albert Einstein',\n",
       " 'André Gide',\n",
       " 'Thomas A. Edison',\n",
       " 'Eleanor Roosevelt',\n",
       " 'Steve Martin']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_author = quote_html.select('div.quote > span > small.author')\n",
    "quote_author_text = [ i.text  for i in quote_author]\n",
    "quote_author_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 동일한 방법을 이용해 말한 사람 역시 손쉽게 추출이 가능합니다.\n",
    "\n",
    "마지막으로 말한 사람에 대한 정보인 (about)에 해당하는 링크도 추출해보자. 해당 주소는 [class가 quote인 div 태그] 하단의 [span 태그], 다시 하단의 [a 태그의 href 속성] 중 속성값에 위치하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/author/Albert-Einstein\">(about)</a>,\n",
       " <a href=\"/author/J-K-Rowling\">(about)</a>,\n",
       " <a href=\"/author/Albert-Einstein\">(about)</a>,\n",
       " <a href=\"/author/Jane-Austen\">(about)</a>,\n",
       " <a href=\"/author/Marilyn-Monroe\">(about)</a>,\n",
       " <a href=\"/author/Albert-Einstein\">(about)</a>,\n",
       " <a href=\"/author/Andre-Gide\">(about)</a>,\n",
       " <a href=\"/author/Thomas-A-Edison\">(about)</a>,\n",
       " <a href=\"/author/Eleanor-Roosevelt\">(about)</a>,\n",
       " <a href=\"/author/Steve-Martin\">(about)</a>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_link = quote_html.select('div.quote > span > a')\n",
    "quote_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 중에서 우리는 속성값에 해당하는 정보만 필요하다. 속성값의 경우 HTML 정보 뒤에 ['속성']을 입력하면 추출할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/author/Albert-Einstein',\n",
       " '/author/J-K-Rowling',\n",
       " '/author/Albert-Einstein',\n",
       " '/author/Jane-Austen',\n",
       " '/author/Marilyn-Monroe',\n",
       " '/author/Albert-Einstein',\n",
       " '/author/Andre-Gide',\n",
       " '/author/Thomas-A-Edison',\n",
       " '/author/Eleanor-Roosevelt',\n",
       " '/author/Steve-Martin']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_link[0]['href']\n",
    "# 모든 속성을 출력해 보세요 리스트컴프리헨션을 이용해서\n",
    "quote_link_list = [ i['href'] for i in quote_link ]\n",
    "quote_link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 속성값을 한 번에 추출한 후, 완전한 URL을 만들기 위해 주소 부분도 합쳐주도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://quotes.toscrape.com/author/Albert-Einstein',\n",
       " 'https://quotes.toscrape.com/author/J-K-Rowling',\n",
       " 'https://quotes.toscrape.com/author/Albert-Einstein',\n",
       " 'https://quotes.toscrape.com/author/Jane-Austen',\n",
       " 'https://quotes.toscrape.com/author/Marilyn-Monroe',\n",
       " 'https://quotes.toscrape.com/author/Albert-Einstein',\n",
       " 'https://quotes.toscrape.com/author/Andre-Gide',\n",
       " 'https://quotes.toscrape.com/author/Thomas-A-Edison',\n",
       " 'https://quotes.toscrape.com/author/Eleanor-Roosevelt',\n",
       " 'https://quotes.toscrape.com/author/Steve-Martin']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_link_list = ['https://quotes.toscrape.com' + i['href'] for i in quote_link ]\n",
    "quote_link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모든 페이지 데이터 크롤링하기\n",
    "\n",
    "화면 하단의 [Next→] 부분을 클릭하면 URL이 https://quotes.toscrape.com/page/2/ 로 바뀌며 다음 페이지의 내용이 나타난다. 이처럼 웹페이지 하단에서 다음 페이지 혹은 이전 페이지로 넘어가게 해주는 것을 흔히 페이지네이션이라고 한다. \n",
    "\n",
    "```{figure} image/crawl_basic/pagination.png\n",
    "---\n",
    "name: pagination\n",
    "---\n",
    "페이지네이션\n",
    "```\n",
    "\n",
    "URL의 'page/' 뒤에 위치하는 숫자를 for문을 이용해 바꿔준다면, 모든 페이지의 데이터를 크롤링할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "\n",
    "text_list = [] #모든 페이지 명언 리스트\n",
    "author_list = [] #모든 페이지 작성자 리스트\n",
    "infor_list = [] #모든 페이지 사이트 링크 리스트\n",
    "\n",
    "for i in range(1, 100):\n",
    "    url = f'https://quotes.toscrape.com/page/{i}/'\n",
    "    quote = rq.get(url)\n",
    "    quote_html = bs(quote.content, 'lxml')\n",
    "    quote_text = quote_html.select('div.quote > span.text')\n",
    "    quote_text_list = [i.text for i in quote_text] #한개의 명언 \n",
    "    quote_author = quote_html.select('div.quote > span > small.author')\n",
    "    quote_author_list = [i.text for i in quote_author] # 한명의 작성자\n",
    "    # 작성자를 이용한 링크 주소\n",
    "    quote_link = quote_html.select('div.quote > span > a')\n",
    "    quote_link_list=[ 'https://quotes.toscrape.com'+i['href'] for i in quote_link ]\n",
    "\n",
    "    if len(quote_text_list) > 0 :\n",
    "        text_list.extend( quote_text_list )\n",
    "        author_list.extend( quote_author_list )\n",
    "        infor_list.extend( quote_link_list )\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 명언과 말한 사람, 링크가 들어갈 빈 리스트(text_list, author_list, infor_list)를 만든다.\n",
    "2. for문을 1부터 100까지 적용하여 URL을 생성한다.\n",
    "3. HTML 정보를 받아온 후 `BeautifulSoup()` 함수를 통해 파싱한다.\n",
    "4. 명언과 말한 사람, 링크에 해당하는 내용을 각각 추출한다.\n",
    "5. 해당 웹페이지는 10페이지까지 데이터가 존재하며, 11페이지부터는 아무런 내용이 없다. 그러나 이러한 정보는 사전에 알 수 없기에 만약 데이터가 있는 경우 위에서 생성한 리스트에 `extend()` 함수를 사용하여 데이터를 추가하며, 그렇지 않을 경우 `break`를 통해 for문을 종료한다.\n",
    "6. 한 번 루프가 돌때마다 1초간 정지를 준다.\n",
    "\n",
    "text_list와 author_list, infor_list를 확인해보면 모든 페이지의 내용이 저장되어 있다. 이제 크롤링 한 내용을 데이터프레임 형태로 만들도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>infor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>https://quotes.toscrape.com/author/J-K-Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>https://quotes.toscrape.com/author/Jane-Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>https://quotes.toscrape.com/author/Marilyn-Monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>https://quotes.toscrape.com/author/Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>https://quotes.toscrape.com/author/Madeleine-L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>https://quotes.toscrape.com/author/Mark-Twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>https://quotes.toscrape.com/author/Dr-Seuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>https://quotes.toscrape.com/author/George-R-R-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text              author  \\\n",
       "0   “The world as we have created it is a process ...     Albert Einstein   \n",
       "1   “It is our choices, Harry, that show what we t...        J.K. Rowling   \n",
       "2   “There are only two ways to live your life. On...     Albert Einstein   \n",
       "3   “The person, be it gentleman or lady, who has ...         Jane Austen   \n",
       "4   “Imperfection is beauty, madness is genius and...      Marilyn Monroe   \n",
       "..                                                ...                 ...   \n",
       "95  “You never really understand a person until yo...          Harper Lee   \n",
       "96  “You have to write the book that wants to be w...   Madeleine L'Engle   \n",
       "97  “Never tell the truth to people who are not wo...          Mark Twain   \n",
       "98        “A person's a person, no matter how small.”           Dr. Seuss   \n",
       "99  “... a mind needs books as a sword needs a whe...  George R.R. Martin   \n",
       "\n",
       "                                                infor  \n",
       "0   https://quotes.toscrape.com/author/Albert-Eins...  \n",
       "1      https://quotes.toscrape.com/author/J-K-Rowling  \n",
       "2   https://quotes.toscrape.com/author/Albert-Eins...  \n",
       "3      https://quotes.toscrape.com/author/Jane-Austen  \n",
       "4   https://quotes.toscrape.com/author/Marilyn-Monroe  \n",
       "..                                                ...  \n",
       "95      https://quotes.toscrape.com/author/Harper-Lee  \n",
       "96  https://quotes.toscrape.com/author/Madeleine-L...  \n",
       "97      https://quotes.toscrape.com/author/Mark-Twain  \n",
       "98        https://quotes.toscrape.com/author/Dr-Seuss  \n",
       "99  https://quotes.toscrape.com/author/George-R-R-...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list\n",
    "author_list\n",
    "infor_list\n",
    "import pandas as pd\n",
    "df = pd.DataFrame( {'text': text_list, 'author': author_list, 'infor': infor_list} )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금융 속보 크롤링\n",
    "\n",
    "이번에는 금융 속보의 제목을 추출해보겠다. 먼저 네이버 금융에 접속한 후 [뉴스 → 실시간 속보]를 선택하며, URL은 다음과 같다. \n",
    "\n",
    "```\n",
    "https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258\n",
    "```\n",
    "\n",
    "이 중 뉴스의 제목에 해당하는 텍스트만 추출해보도록 하자. 개발자도구 화면을 통헤 제목에 해당하는 부분은 [dl 태그 → class가 articleSubject 인 dd 태그 → a 태그 중 title 속성]에 위치하고 있음을 확인할 수 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/naver_news.png\n",
    "---\n",
    "name: naver_news\n",
    "---\n",
    "실시간 속보의 제목 부분 HTML\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/news/news_read.naver?article_id=0000384489&amp;office_id=629&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"거래소, 기승 부리는 '정치 테마주' 투자 유의 안내\">거래소, 기승 부리는 '정치 테마주' 투자 유의 안내</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0000384487&amp;office_id=629&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"SK증권, 여의도 담배꽁초 줍는 ESG 환경 캠페인 진행\">SK증권, 여의도 담배꽁초 줍는 ESG 환경 캠페인 진행</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005481232&amp;office_id=009&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"‘머스크 복귀 예고’에 테슬라 이어 韓 2차전지주도 강세\">‘머스크 복귀 예고’에 테슬라 이어 韓 2차전지주도 강세</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005184776&amp;office_id=008&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"NH투자증권, 효과적인 대화법 주제 100세시대 아카데미 개최\">NH투자증권, 효과적인 대화법 주제 100세시대 아카데미 개최</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005481231&amp;office_id=009&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"금감원 제동에도 유증 재도전 나선 스맥, 다윗의 골리앗 인수 가능할까\">금감원 제동에도 유증 재도전 나선 스맥, 다윗의 골리앗 인수 가능할까</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005481229&amp;office_id=009&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"“이럴 땐 팔아야해 사야해?”…전문가가 본 金값 전망은?\">“이럴 땐 팔아야해 사야해?”…전문가가 본 金값 전망은?</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0001072830&amp;office_id=417&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"KT&amp;G, 카자흐스탄 신공장 준공… 유라시아 수출 전초기지 구축\">KT&amp;G, 카자흐스탄 신공장 준공… 유라시아 수출 전초기지 구축</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0001206870&amp;office_id=215&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title='\"연이은 임상\"…이상훈 에이비엘바이오 대표 \"5년 후 FDA 신약 허가 계획\"'>\"연이은 임상\"…이상훈 에이비엘바이오 대표 \"5년 후 FDA 신약 허가 계획\"</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0015347134&amp;office_id=001&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title='신한은행 \"신탁형 ISA 수탁고 5조원 넘어\"'>신한은행 \"신탁형 ISA 수탁고 5조원 넘어\"</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005122966&amp;office_id=015&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"유안타증권 'EDC KOREA 2025' 스폰서 참여\">유안타증권 'EDC KOREA 2025' 스폰서 참여</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005481218&amp;office_id=009&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"MG캐피탈 2천억 유증…8.5% 고금리 대출 상환 나선다\">MG캐피탈 2천억 유증…8.5% 고금리 대출 상환 나선다</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0015347091&amp;office_id=001&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"이달 '투자경고·위험' 종목 80%는 정치테마주…&quot;불공정거래 강력대처&quot;\">이달 '투자경고·위험' 종목 80%는 정치테마주…\"불공정거래 강력대처\"</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0001206868&amp;office_id=215&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"5년만에 역성장...편의점, 해외 노린다 [마켓딥다이브]\">5년만에 역성장...편의점, 해외 노린다 [마켓딥다이브]</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0004477490&amp;office_id=011&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"딥노이드, 연세대 공과대학과 의료영상·AI 공동 연구 협약 체결\">딥노이드, 연세대 공과대학과 의료영상·AI 공동 연구 협약 체결</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0001206866&amp;office_id=215&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"한국경제TV, 찾아가는 해외주식 무료 현장세미나 26일 개최\">한국경제TV, 찾아가는 해외주식 무료 현장세미나 26일 개최</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0005995205&amp;office_id=018&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"트럼프 관세전쟁에 '셀 아메리카'…유럽펀드로 갈아타는 투자자들\">트럼프 관세전쟁에 '셀 아메리카'…유럽펀드로 갈아타는 투자자들</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0004477487&amp;office_id=011&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"증여 소식에 한미반도체 13% 상승 '훨훨' [줍줍리포트]\">증여 소식에 한미반도체 13% 상승 '훨훨' [줍줍리포트]</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0015347030&amp;office_id=001&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"김소영 금융위 부위원장, ESG 금융추진단 제5차 회의\">김소영 금융위 부위원장, ESG 금융추진단 제5차 회의</a>,\n",
       " <a href=\"/news/news_read.naver?article_id=0015347029&amp;office_id=001&amp;mode=LSS2D&amp;type=0&amp;section_id=101&amp;section_id2=258&amp;section_id3=&amp;date=20250423&amp;page=1\" title=\"김소영 금융위 부위원장, ESG 금융추진단 제5차 회의\">김소영 금융위 부위원장, ESG 금융추진단 제5차 회의</a>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests as rq\n",
    "url = 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258'\n",
    "quote = rq.get(url)\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "quote_html = bs( quote.content, 'lxml' )\n",
    "\n",
    "quote_a=quote_html.select('dl > dd.articleSubject > a')\n",
    "quote_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `get()` 함수를 이용해 페이지의 내용을 받아온다.\n",
    "2. `BeautifulSoup()` 함수를 통해 HTML 정보를 BeautifulSoup 객체로 만든다.\n",
    "3. `select()` 함수를 통해 원하는 태그로 접근해 들어간다. \n",
    "\n",
    "출력된 내용을 살펴 보면 우리가 원하는 제목은 title 속성에 위치하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"거래소, 기승 부리는 '정치 테마주' 투자 유의 안내\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_a[0]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "속성값에 해당하는 내용을 추출했다. 이제 for문으로 묶어 한번에 제목들을 추출하도록 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"거래소, 기승 부리는 '정치 테마주' 투자 유의 안내\",\n",
       " 'SK증권, 여의도 담배꽁초 줍는 ESG 환경 캠페인 진행',\n",
       " '‘머스크 복귀 예고’에 테슬라 이어 韓 2차전지주도 강세',\n",
       " 'NH투자증권, 효과적인 대화법 주제 100세시대 아카데미 개최',\n",
       " '금감원 제동에도 유증 재도전 나선 스맥, 다윗의 골리앗 인수 가능할까',\n",
       " '“이럴 땐 팔아야해 사야해?”…전문가가 본 金값 전망은?',\n",
       " 'KT&G, 카자흐스탄 신공장 준공… 유라시아 수출 전초기지 구축',\n",
       " '\"연이은 임상\"…이상훈 에이비엘바이오 대표 \"5년 후 FDA 신약 허가 계획\"',\n",
       " '신한은행 \"신탁형 ISA 수탁고 5조원 넘어\"',\n",
       " \"유안타증권 'EDC KOREA 2025' 스폰서 참여\",\n",
       " 'MG캐피탈 2천억 유증…8.5% 고금리 대출 상환 나선다',\n",
       " '이달 \\'투자경고·위험\\' 종목 80%는 정치테마주…\"불공정거래 강력대처\"',\n",
       " '5년만에 역성장...편의점, 해외 노린다 [마켓딥다이브]',\n",
       " '딥노이드, 연세대 공과대학과 의료영상·AI 공동 연구 협약 체결',\n",
       " '한국경제TV, 찾아가는 해외주식 무료 현장세미나 26일 개최',\n",
       " \"트럼프 관세전쟁에 '셀 아메리카'…유럽펀드로 갈아타는 투자자들\",\n",
       " \"증여 소식에 한미반도체 13% 상승 '훨훨' [줍줍리포트]\",\n",
       " '김소영 금융위 부위원장, ESG 금융추진단 제5차 회의',\n",
       " '김소영 금융위 부위원장, ESG 금융추진단 제5차 회의']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_title = [i['title'] for i in quote_a]\n",
    "quote_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>거래소, 기승 부리는 '정치 테마주' 투자 유의 안내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SK증권, 여의도 담배꽁초 줍는 ESG 환경 캠페인 진행</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘머스크 복귀 예고’에 테슬라 이어 韓 2차전지주도 강세</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NH투자증권, 효과적인 대화법 주제 100세시대 아카데미 개최</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>금감원 제동에도 유증 재도전 나선 스맥, 다윗의 골리앗 인수 가능할까</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“이럴 땐 팔아야해 사야해?”…전문가가 본 金값 전망은?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KT&amp;G, 카자흐스탄 신공장 준공… 유라시아 수출 전초기지 구축</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"연이은 임상\"…이상훈 에이비엘바이오 대표 \"5년 후 FDA 신약 허가 계획\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>신한은행 \"신탁형 ISA 수탁고 5조원 넘어\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>유안타증권 'EDC KOREA 2025' 스폰서 참여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MG캐피탈 2천억 유증…8.5% 고금리 대출 상환 나선다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>이달 '투자경고·위험' 종목 80%는 정치테마주…\"불공정거래 강력대처\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5년만에 역성장...편의점, 해외 노린다 [마켓딥다이브]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>딥노이드, 연세대 공과대학과 의료영상·AI 공동 연구 협약 체결</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>한국경제TV, 찾아가는 해외주식 무료 현장세미나 26일 개최</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>트럼프 관세전쟁에 '셀 아메리카'…유럽펀드로 갈아타는 투자자들</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>증여 소식에 한미반도체 13% 상승 '훨훨' [줍줍리포트]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>김소영 금융위 부위원장, ESG 금융추진단 제5차 회의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>김소영 금융위 부위원장, ESG 금융추진단 제5차 회의</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title\n",
       "0                 거래소, 기승 부리는 '정치 테마주' 투자 유의 안내\n",
       "1               SK증권, 여의도 담배꽁초 줍는 ESG 환경 캠페인 진행\n",
       "2               ‘머스크 복귀 예고’에 테슬라 이어 韓 2차전지주도 강세\n",
       "3            NH투자증권, 효과적인 대화법 주제 100세시대 아카데미 개최\n",
       "4        금감원 제동에도 유증 재도전 나선 스맥, 다윗의 골리앗 인수 가능할까\n",
       "5               “이럴 땐 팔아야해 사야해?”…전문가가 본 金값 전망은?\n",
       "6           KT&G, 카자흐스탄 신공장 준공… 유라시아 수출 전초기지 구축\n",
       "7   \"연이은 임상\"…이상훈 에이비엘바이오 대표 \"5년 후 FDA 신약 허가 계획\"\n",
       "8                     신한은행 \"신탁형 ISA 수탁고 5조원 넘어\"\n",
       "9                 유안타증권 'EDC KOREA 2025' 스폰서 참여\n",
       "10              MG캐피탈 2천억 유증…8.5% 고금리 대출 상환 나선다\n",
       "11      이달 '투자경고·위험' 종목 80%는 정치테마주…\"불공정거래 강력대처\"\n",
       "12              5년만에 역성장...편의점, 해외 노린다 [마켓딥다이브]\n",
       "13          딥노이드, 연세대 공과대학과 의료영상·AI 공동 연구 협약 체결\n",
       "14            한국경제TV, 찾아가는 해외주식 무료 현장세미나 26일 개최\n",
       "15           트럼프 관세전쟁에 '셀 아메리카'…유럽펀드로 갈아타는 투자자들\n",
       "16             증여 소식에 한미반도체 13% 상승 '훨훨' [줍줍리포트]\n",
       "17               김소영 금융위 부위원장, ESG 금융추진단 제5차 회의\n",
       "18               김소영 금융위 부위원장, ESG 금융추진단 제5차 회의"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({ 'title': quote_title })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테이블 크롤링하기\n",
    "\n",
    "우리가 크롤링하고자 하는 데이터가 테이블 형태로 제공될 경우, 위와 같이 복잡한 과정을 거칠 필요 없이 매우 간단하게 테이블에 해당하는 내용만 가져올 수 있다. 먼저 아래 사이트에는 각 국가별 GDP가 테이블 형태로 제공되고 있다.\n",
    "\n",
    "```\n",
    "https://en.wikipedia.org/wiki/List_of_countries_by_stock_market_capitalization\n",
    "```\n",
    "\n",
    "```{figure} image/crawl_basic/cap.png\n",
    "---\n",
    "name: cap\n",
    "---\n",
    "국가별 시가총액 데이터\n",
    "```\n",
    "\n",
    "해당 내역을 크롤링하는 법은 매우 간단하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vteEconomic classification of countries</th>\n",
       "      <th>vteEconomic classification of countries.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Developed country Developing country Heavily i...</td>\n",
       "      <td>Developed country Developing country Heavily i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three/Four-World Model</td>\n",
       "      <td>First World Second World Third World Fourth World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gross domestic product (GDP)</td>\n",
       "      <td>Nominal By country past and projected per capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nominal</td>\n",
       "      <td>By country past and projected per capita per c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purchasing power parity (PPP)</td>\n",
       "      <td>By country future estimates per capita per cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Income</td>\n",
       "      <td>GNI (nominal) per capita GNI (PPP) per capita ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wages</td>\n",
       "      <td>Average wage Europe Employee compensation (per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wealth</td>\n",
       "      <td>Wealth per adult Europe Financial assets per c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other national accounts</td>\n",
       "      <td>Gross National Happiness Net material product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Human development</td>\n",
       "      <td>Human Development Index by country inequality-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Digital divide</td>\n",
       "      <td>ICT Development Index Number of broadband Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Net international investment position (NIIP)</td>\n",
       "      <td>Per capita (creditors) Per capita (debtors)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Economics portal  World portal</td>\n",
       "      <td>Economics portal  World portal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vteEconomic classification of countries  \\\n",
       "0   Developed country Developing country Heavily i...   \n",
       "1                              Three/Four-World Model   \n",
       "2                        Gross domestic product (GDP)   \n",
       "3                                             Nominal   \n",
       "4                       Purchasing power parity (PPP)   \n",
       "5                                              Income   \n",
       "6                                               Wages   \n",
       "7                                              Wealth   \n",
       "8                             Other national accounts   \n",
       "9                                   Human development   \n",
       "10                                     Digital divide   \n",
       "11       Net international investment position (NIIP)   \n",
       "12                     Economics portal  World portal   \n",
       "\n",
       "            vteEconomic classification of countries.1  \n",
       "0   Developed country Developing country Heavily i...  \n",
       "1   First World Second World Third World Fourth World  \n",
       "2   Nominal By country past and projected per capi...  \n",
       "3   By country past and projected per capita per c...  \n",
       "4   By country future estimates per capita per cap...  \n",
       "5   GNI (nominal) per capita GNI (PPP) per capita ...  \n",
       "6   Average wage Europe Employee compensation (per...  \n",
       "7   Wealth per adult Europe Financial assets per c...  \n",
       "8   Gross National Happiness Net material product ...  \n",
       "9   Human Development Index by country inequality-...  \n",
       "10  ICT Development Index Number of broadband Inte...  \n",
       "11        Per capita (creditors) Per capita (debtors)  \n",
       "12                     Economics portal  World portal  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_stock_market_capitalization'\n",
    "df_list = pd.read_html(url) #사이트에 <table>테그를 리스트로 가져온다\n",
    "df_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. URL을 입력한다.\n",
    "2. pandas 패키지의 `read_html()` 함수에 URL을 입력하면, 해당 페이지에 존재하는 테이블을 가져온 후 데이터프레임 형태로 불러온다. \n",
    "\n",
    "이처럼 테이블 형태로 존재하는 데이터는 HTML 정보를 불러온 후 태그와 속성을 찾을필요 없이 `read_html()` 함수를 이용해 매우 손쉽게 불러올 수 있다.\n",
    "\n",
    "### 기업공시채널에서 오늘의 공시 불러오기\n",
    "\n",
    "한국거래소 상장공시시스템(kind.krx.co.kr)에 접속한 후 [오늘의 공시 → 전체 → 더보기]를 선택해 전체 공시내용을 확인할 수 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/kind.png\n",
    "---\n",
    "name: kind\n",
    "---\n",
    "오늘의공시 확인하기\n",
    "```\n",
    "\n",
    "해당 페이지에서 날짜를 변경한 후 [검색]을 누르면, 페이지의 내용은 해당일의 공시로 변경되지만 URL은 변경되지 않는다. 이처럼 POST 방식은 요청하는 데이터에 대한 쿼리가 body의 형태를 통해 전송되므로, 개발자도구 화면을 통해 해당 쿼리에 대한 내용을 확인해야 한다.\n",
    "\n",
    "개발자도구 화면을 연 상태에서 조회일자를 원하는 날짜로 선택, [검색]을 클릭한 후 [Network] 탭의 todaydisclosure.do 항목에서 [Headers]탭의 [General] 부분에는 데이터를 요청하는 서버 주소가, [Payload] 탭의 [Form Data]를 통해 서버에 데이터를 요청하는 내역을 확인할 수 있다. 여러 항목 중 selDate 부분이 우리가 선택한 일자로 설정되어 있다.\n",
    "\n",
    "```{figure} image/crawl_basic/kind_post.png\n",
    "---\n",
    "name: kind_post\n",
    "---\n",
    "POST 방식의 데이터 요청\n",
    "```\n",
    "\n",
    "POST 방식으로 쿼리를 요청하는 방법을 코드로 나타내면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do'\n",
    "payload = {\n",
    "    'method': 'searchTodayDisclosureSub',\n",
    "    'currentPageSize': 15,\n",
    "    'pageIndex': 1,\n",
    "    'orderMode': 0,\n",
    "    'orderStat': 'D',\n",
    "    'forward': 'todaydisclosure_sub',\n",
    "    'chose': 'S',\n",
    "    'todayFlag': 'N',\n",
    "    'selDate': '2025-04-23'\n",
    " }\n",
    "quote = rq.post(url, data=payload) # payload 웹페이지에 대한 정보를 딕셔너리\n",
    "quote\n",
    "quote_html = bs(quote.content, 'lxml')\n",
    "#quote_html\n",
    "#여기서 날자를 4월 23일로 바꾸려면 selDate값을 바꾸기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```{figure} image/crawl_basic/html.png\n",
    "---\n",
    "name: html\n",
    "---\n",
    "```\n",
    "\n",
    "1. URL과 쿼리를 입력한다. 쿼리는 딕셔너리 형태로 입력하며, Form Data와 동일하게 입력해준다. 쿼리 중 marketType과 같이 값이 없는 항목은 입력하지 않아도 된다.\n",
    "2. `POST()` 함수를 통해 해당 URL에 원하는 쿼리를 요청한다.\n",
    "3. `BeautifulSoup()` 함수를 통해 파싱한다.\n",
    "\n",
    "읽어온 데이터를 확인해보면 엑셀 데이터가 HTML 형태로 나타나있다. 따라서 이를 변형해 데이터프레임 형태로 불러오도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_unicode = quote_html.prettify()\n",
    "#html_unicode[500:1000]\n",
    "#html_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_4068\\864931435.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(html_unicode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                                0  \\\n",
       " 0  오늘  04.22 (화)  04.21 (월)  04.18 (금)  04.17 (목)   \n",
       " 1                                             회사명   \n",
       " \n",
       "                                                 1  \n",
       " 0  오늘  04.22 (화)  04.21 (월)  04.18 (금)  04.17 (목)  \n",
       " 1                                              찾기  ]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html(html_unicode)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `prettify()` 함수를 이용해 BeautifulSoup 에서 파싱한 파서 트리를 유니코드 형태로 다시 돌려준다.\n",
    "2. `read_html()` 함수를 통해 테이블을 읽어온다.\n",
    "\n",
    "데이터를 확인하면 화면과 동일한 내용이 들어가있다. POST 형식의 경우 쿼리 내용을 바꾸어 원하는 데이터를 받을 수 있다. 만일 다른 날짜의 공시를 확인하고자 한다면 위의 코드에서 'selDate'만 해당일로 변경해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do'\n",
    "payload = {\n",
    "    'method': 'searchTodayDisclosureSub',\n",
    "    'currentPageSize': '15',\n",
    "    'pageIndex': '1',\n",
    "    'orderMode': '0',\n",
    "    'orderStat': 'D',\n",
    "    'forward': 'todaydisclosure_sub',\n",
    "    'chose': 'S',\n",
    "    'todayFlag': 'N',\n",
    "    'selDate': '2025-04-23'\n",
    "}\n",
    "\n",
    "data = rq.post(url, data=payload)\n",
    "html = BeautifulSoup(data.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_4068\\1205700952.py:2: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tbl = pd.read_html(html.prettify())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16:07</td>\n",
       "      <td>코어라인소프트</td>\n",
       "      <td>[정정]  투자설명서</td>\n",
       "      <td>코어라인소프트</td>\n",
       "      <td>공시차트  주가차트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16:07</td>\n",
       "      <td>에어부산</td>\n",
       "      <td>영업(잠정)실적(공정공시)</td>\n",
       "      <td>에어부산</td>\n",
       "      <td>공시차트  주가차트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16:06</td>\n",
       "      <td>지니틱스</td>\n",
       "      <td>주주총회소집결의(임시주주총회)</td>\n",
       "      <td>지니틱스</td>\n",
       "      <td>공시차트  주가차트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16:06</td>\n",
       "      <td>미스토홀딩스</td>\n",
       "      <td>주식등의대량보유상황보고서(일반)</td>\n",
       "      <td>피에몬테</td>\n",
       "      <td>공시차트  주가차트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16:06</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>[연결포함]  일괄신고추가서류(파생결합증권-주가연계증권)</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>공시차트  주가차트</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 1                       Unnamed: 2 Unnamed: 3  \\\n",
       "0      16:07    코어라인소프트                      [정정]  투자설명서    코어라인소프트   \n",
       "1      16:07       에어부산                   영업(잠정)실적(공정공시)       에어부산   \n",
       "2      16:06       지니틱스                 주주총회소집결의(임시주주총회)       지니틱스   \n",
       "3      16:06     미스토홀딩스                주식등의대량보유상황보고서(일반)       피에몬테   \n",
       "4      16:06     한화투자증권  [연결포함]  일괄신고추가서류(파생결합증권-주가연계증권)     한화투자증권   \n",
       "\n",
       "   Unnamed: 4  \n",
       "0  공시차트  주가차트  \n",
       "1  공시차트  주가차트  \n",
       "2  공시차트  주가차트  \n",
       "3  공시차트  주가차트  \n",
       "4  공시차트  주가차트  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_unicode = html.prettify()\n",
    "tbl = pd.read_html(html.prettify())\n",
    "\n",
    "tbl[0].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
